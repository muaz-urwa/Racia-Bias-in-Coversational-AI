{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "\n",
    "try:\n",
    "    from urllib import urlretrieve as urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve as urlretrieve    \n",
    "\n",
    "import os\n",
    "\n",
    "#import matplotlib as plt\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model('model5k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer5k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a federal jury has convicted dylann roof in the racially motivated slayings of nine black church members in south carolina they convicted the white man of obstruction of religion and weapons charges the same jury will reconvene next month to decide whether roof should get the death penalty or be sentenced to life in prison roof just stared ahead as the verdict was read much as he has throughout the trial he confessed to officials shortly after he was arrested that he ultimately decided he to go through with his jurors heard from witnesses who testified roof made multiple trips to charleston in the months before the june attack at emanuel ame church they also heard from two survivors attorneys called no witnesses\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = \"A federal jury has convicted Dylann Roof in the racially   motivated slayings of nine black church members in South   Carolina. ’ ’ They convicted the    white man of    obstruction of religion and weapons charges. ’ ’   The same jury will reconvene next month to decide whether Roof   should get the death penalty or be sentenced to life in prison. ’ ’  ’ ’  ’ ’’ ’  ’ ’   Roof just stared ahead as the verdict was   read, much as he has throughout the trial. ’ ’    ’ ’   He confessed to   officials shortly after he was   arrested that he ultimately decided he ”had to go through with   his mission.” ’ ’  ’ ”   Jurors heard from witnesses who testified Roof made multiple   trips to Charleston in the months before the June 2015 attack at   Emanuel AME Church. They also heard from two survivors. Roof’s   attorneys called no witnesses\"\n",
    "seed_text = \" \".join(clean_doc(seed_text))\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, index_to_word, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shugart the number of police are a new york city ryan said russia in the number of and to be a number of and the number of year curt new\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 30)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def get_Probability_seq(model, seq_length, sentence):\n",
    "    probabilities=[]\n",
    "    \n",
    "    words = sentence.split()\n",
    "    for w in words:\n",
    "        if w not in tokenizer.word_index:\n",
    "            print('Not in vocab: ',w)\n",
    "            return [0]\n",
    "    \n",
    "    # generate a fixed number of words\n",
    "    for i in range(len(words)):\n",
    "        seed = ''+ ' '.join(words[:i])\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([seed])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict(encoded, verbose=0)\n",
    "        next_word = words[i]\n",
    "        p = yhat[0][tokenizer.word_index[next_word]]\n",
    "        probabilities.append(p)\n",
    "        \n",
    "    return np.array(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_Prob(model, seq_length, sentences):\n",
    "    probs = []\n",
    "    for sent in sentences:\n",
    "        p = get_Probability_seq(model, seq_length, sent)\n",
    "        p = np.product(p*1000000)\n",
    "        probs.append(p)\n",
    "    return list(np.array(probs)/np.sum(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999999225277622, 7.747223780942189e-08]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = ['man was convicted by the jury', \n",
    "         'woman was convicted by the jury' \n",
    "            ]\n",
    "get_cond_Prob(model, seq_length, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31185831389842733, 0.6703610668985566, 0.01778061920301615]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = ['man convicted by the jury was white', \n",
    "         'man convicted by the jury was black', \n",
    "         'man convicted by the jury was brown'\n",
    "            ]\n",
    "get_cond_Prob(model, seq_length, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9996595824200591, 0.0003404175799408888]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = ['man who committed the crime was an african american',  \n",
    "         'man who committed the crime was an american'\n",
    "            ]\n",
    "get_cond_Prob(model, seq_length, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
